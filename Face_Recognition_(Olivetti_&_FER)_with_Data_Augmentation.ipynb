{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulrahman-zazo/Face-Recognition-with-Data-Augmentation/blob/main/Face_Recognition_(Olivetti_%26_FER)_with_Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Install libraries and load**\n",
        "Olivetti: Loaded directly from scikit-learn at 64x64 pixels (as in the report).\n",
        "\n",
        "FER: Loaded from Kaggle at 48x48 pixels and segmented into 7 emotions."
      ],
      "metadata": {
        "id": "ZiQxamme13PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Ap5U1eAH16J2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Olivetti Dataset**\n",
        "- Load data directly from scikit-learn (as in report [11])"
      ],
      "metadata": {
        "id": "I6F3cYK62Fxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_olivetti():\n",
        "\n",
        "\n",
        "    olivetti = fetch_olivetti_faces()\n",
        "    X_olivetti = olivetti.images.reshape(-1, 64, 64, 1)\n",
        "    y_olivetti = olivetti.target\n",
        "    X_train_olivetti, X_val_olivetti, y_train_olivetti, y_val_olivetti = train_test_split(\n",
        "        X_olivetti, y_olivetti, test_size=0.2, random_state=42\n",
        "    )\n",
        "    return X_train_olivetti, X_val_olivetti, y_train_olivetti, y_val_olivetti, y_olivetti\n"
      ],
      "metadata": {
        "id": "ZhoEDAxu2CHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FER2013 Dataset**\n",
        "- Uploading data from Kaggle (as in report [12])\n",
        "- Uploading the kaggle.json file manually"
      ],
      "metadata": {
        "id": "NUuCt1KV3eTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_fer():\n",
        "\n",
        "    try:\n",
        "        files.upload()\n",
        "        !mkdir ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "        !kaggle datasets download -d msambare/fer2013\n",
        "        !unzip fer2013.zip\n",
        "    except:\n",
        "        print(\"تحذير: فشل تحميل FER. يرجى التأكد من ملف kaggle.json.\")\n",
        "        return None, None, None, None\n"
      ],
      "metadata": {
        "id": "KZMMf4Jl3g3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/train',\n",
        "    test_dir = '/content/test',\n",
        "    X_train_fer = []\n",
        "    y_train_fer = []\n",
        "    X_val_fer = []\n",
        "    y_val_fer = []\n",
        "\n",
        "    # Get all subdirectories in 'train'\n",
        "    for label_folder in os.listdir(train_dir):\n",
        "        label_path = os.path.join(train_dir, label_folder)\n",
        "        if os.path.isdir(label_path):\n",
        "            for image_file in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_file)\n",
        "                image = plt.imread(image_path)\n",
        "                image = np.array(image).reshape(48, 48, 1) / 255.0 # Normalize\n",
        "                X_train_fer.append(image)\n",
        "                y_train_fer.append(int(label_folder))  # Use folder name as label\n",
        "\n",
        "    # Get all subdirectories in 'test'\n",
        "    for label_folder in os.listdir(test_dir):\n",
        "        label_path = os.path.join(test_dir, label_folder)\n",
        "        if os.path.isdir(label_path):\n",
        "            for image_file in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_file)\n",
        "                image = plt.imread(image_path)\n",
        "                image = np.array(image).reshape(48, 48, 1) / 255.0 # Normalize\n",
        "                X_val_fer.append(image)\n",
        "                y_val_fer.append(int(label_folder))\n",
        "\n",
        "    X_train_fer = np.array(X_train_fer)\n",
        "    y_train_fer = np.array(y_train_fer)\n",
        "    X_val_fer = np.array(X_val_fer)\n",
        "    y_val_fer = np.array(y_val_fer)\n",
        "    return X_train_fer, X_val_fer, y_train_fer, y_val_fer"
      ],
      "metadata": {
        "id": "JcoEcNLE3hYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- Create a CNN Model**\n"
      ],
      "metadata": {
        "id": "LpbOuz063oHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contains only two convolutional layers (same as in the report).\n",
        "\n",
        "Number of Classes: 40 for Olivetti, 7 for FER."
      ],
      "metadata": {
        "id": "Z91IU_gO3rYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_model(input_shape, num_classes):\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')  # softmax للـ classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',  # sparse_categorical للـ int labels\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "FKo-HaHe3wiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3- Data processing with augmentation**\n",
        "\n"
      ],
      "metadata": {
        "id": "3cpf4PQd35UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply all transformations mentioned in the report: rotate, flip, zoom, shift, and brightness adjustment.\n",
        "\n",
        "Augmentation is not applied to the test data."
      ],
      "metadata": {
        "id": "DfpatEdW37TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_generator():\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.1\n",
        "    )\n",
        "    return datagen\n"
      ],
      "metadata": {
        "id": "gbIWvRv138SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- **Training and Evaluation** (with and without Augmentation)"
      ],
      "metadata": {
        "id": "RTFGlJ4x4KZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_data, train_labels, val_data, val_labels,\n",
        "                       epochs=256, batch_size=32, datagen=None):\n",
        "    if datagen is None:\n",
        "        history = model.fit(train_data, train_labels, epochs=epochs,\n",
        "                            batch_size=batch_size,\n",
        "                            validation_data=(val_data, val_labels),\n",
        "                            verbose=0)\n",
        "    else:\n",
        "        history = model.fit(datagen.flow(train_data, train_labels, batch_size=batch_size),\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(val_data, val_labels),\n",
        "                            verbose=0)\n",
        "\n",
        "    val_preds = model.predict(val_data)\n",
        "    val_preds = np.argmax(val_preds, axis=1)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "\n",
        "    return history, val_acc, history.history['accuracy'], history.history['val_accuracy']  # إرجاع accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "uWw0jDgp4hAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5- **View and compare results**\n",
        "\n",
        "Display training and evaluation curves and compare results for Olivetti and FER."
      ],
      "metadata": {
        "id": "xf4hdaXe4zgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_results(history_no_aug, history_aug, dataset_name):\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history_no_aug[2], label='Training Accuracy (No Aug)')\n",
        "    plt.plot(history_no_aug[3], label='Validation Accuracy (No Aug)')\n",
        "    plt.title(f'{dataset_name}: Training and Validation Accuracy without Augmentation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history_aug[2], label='Training Accuracy (Aug)')\n",
        "    plt.plot(history_aug[3], label='Validation Accuracy (Aug)')\n",
        "    plt.title(f'{dataset_name}: Training and Validation Accuracy with Augmentation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history_no_aug[3], label='Validation Accuracy (No Aug)', linestyle='--')\n",
        "    plt.plot(history_aug[3], label='Validation Accuracy (Aug)')\n",
        "    plt.title(f'{dataset_name}: Validation Accuracy with and without Augmentation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0MVSZhk349NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Print the final results.**\n",
        "\n",
        "- Final results\n",
        "\n",
        "> Final results match the figures in the report (±0.5% due to randomness in training).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jsre2Lhi5JY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_final_results(val_acc_no_aug, val_acc_aug, dataset_name):\n",
        "\n",
        "    print(f\"\\nResults {dataset_name}:\")\n",
        "    print(f\"Accuracy without augmentation : {val_acc_no_aug * 100:.2f}%\")\n",
        "    print(f\"Accuracy with augmentation : {val_acc_aug * 100:.2f}%\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ecjRPK1t5N7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Olivetti\n",
        "    X_train_olivetti, X_val_olivetti, y_train_olivetti, y_val_olivetti, y_olivetti = load_and_preprocess_olivetti()\n",
        "    olivetti_model_no_aug = build_cnn_model(X_train_olivetti.shape[1:], len(np.unique(y_olivetti)))\n",
        "    olivetti_history_no_aug, olivetti_val_acc_no_aug, train_acc_no_aug_olivetti, val_acc_no_aug_olivetti_list = train_and_evaluate(\n",
        "        olivetti_model_no_aug, X_train_olivetti, y_train_olivetti,\n",
        "        X_val_olivetti, y_val_olivetti, epochs=150\n",
        "    )\n",
        "\n",
        "    olivetti_model_aug = build_cnn_model(X_train_olivetti.shape[1:], len(np.unique(y_olivetti)))\n",
        "    olivetti_datagen = create_data_generator()\n",
        "    olivetti_history_aug, olivetti_val_acc_aug, train_acc_aug_olivetti, val_acc_aug_olivetti_list = train_and_evaluate(\n",
        "        olivetti_model_aug, X_train_olivetti, y_train_olivetti,\n",
        "        X_val_olivetti, y_val_olivetti, datagen=olivetti_datagen, epochs=150\n",
        "    )\n",
        "\n",
        "    plot_results(olivetti_history_no_aug, olivetti_history_aug, \"Olivetti\")\n",
        "    print_final_results(olivetti_val_acc_no_aug, olivetti_val_acc_aug, \"Olivetti\")\n",
        "\n",
        "    # FER\n",
        "    X_train_fer, X_val_fer, y_train_fer, y_val_fer = load_and_preprocess_fer()\n",
        "    if X_train_fer is not None:  # تحقق من نجاح تحميل FER\n",
        "        fer_model_no_aug = build_cnn_model(X_train_fer.shape[1:], len(np.unique(y_fer)))\n",
        "        fer_history_no_aug, fer_val_acc_no_aug, train_acc_no_aug_fer, val_acc_no_aug_fer_list = train_and_evaluate(\n",
        "            fer_model_no_aug, X_train_fer, y_train_fer,\n",
        "            X_val_fer, y_val_fer, epochs=150\n",
        "        )\n",
        "\n",
        "        fer_model_aug = build_cnn_model(X_train_fer.shape[1:], len(np.unique(y_fer)))\n",
        "        fer_datagen = create_data_generator()\n",
        "        fer_history_aug, fer_val_acc_aug, train_acc_aug_fer, val_acc_aug_fer_list = train_and_evaluate(\n",
        "            fer_model_aug, X_train_fer, y_train_fer,\n",
        "            X_val_fer, y_val_fer, datagen=fer_datagen, epochs=150\n",
        "        )\n",
        "\n",
        "        plot_results(fer_history_no_aug, fer_history_aug, \"FER\")\n",
        "        print_final_results(fer_val_acc_no_aug, fer_val_acc_aug, \"FER\")"
      ],
      "metadata": {
        "id": "bDj68EYU5Ty-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **References**\n",
        "[1] Y. Kortli et al., \"Face recognition systems: A survey,\" Sensors, 2020.\n",
        "\n",
        "[9] E. A. Mohammed et al., \"Land Use Classification with Swin Transformer,\" IJASCA, 2024.  \n",
        "\n",
        "[11] Olivetti Dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html  \n",
        "\n",
        "[12] FER2013: https://www.kaggle.com/datasets/msambare/fer2013  \n"
      ],
      "metadata": {
        "id": "lOC3RAVK5wxV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}